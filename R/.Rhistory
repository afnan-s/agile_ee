install.packages("wordnet")
install.packages("wordnet")
library("wordnet")
WNHOME
initDict()
Sys.getenv("WNHOME")
remove.packages("wordnet")
library("wordnet")
filter <- getTermFilter("ExactMatchFilter", "image", TRUE)
terms <- getIndexTerms("NOUN",1,filter)
getSynonyms(terms[[1]])
synonyms("image","VERB")
synonyms("view","VERB")
install.packages('causla impact')
install.packages('causalimpact')
install.packages("devtools")
library(devtools)
devtools::install_github("google/CausalImpact")
package(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("google/CausalImpact")
session_info()
install.packages('BoomSpikeSlab')
library(devtools)
devtools::install_github("google/CausalImpact")
library(CausalImpact)
set.seed(1)
x1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)
y <- 1.2 * x1 + rnorm(100)
y[71:100] <- y[71:100] + 10
data <- cbind(y, x1)
dim(data)
pre.period <- c(1, 70)
post.period <- c(71, 100)
impact <- CausalImpact(data, pre.period, post.period)
plot(impact)
summary(impact)
impact <- CausalImpact(data, pre.period, post.period, model.args = list(niter = 5000, nseasons = 7))
require(likert)
demo('likert', package='likert')
install.packages()
install.packages('ddply')
plot(l24, colors=c('orange','darkorange','darkblue','blue'))
plot(l24, include.histogram=TRUE)
require(grid)
require(plyr)
plot(l24, include.histogram=TRUE)
plot(l24, type='density')
plot(l24, type='density', facet=FALSE)
plot(l24, type='heat', wrap=30, text.size=4)
items24.reverse <- reverse.levels(items24)
l24.reverse <- likert(items24.reverse)
print(l24.reverse)
plot(l24.reverse)
l24g <- likert(items24, grouping=pisaitems$CNT)
print(l24g)
summary(l24g)
summary(l24g, center=1.5)
summary(l24g, center=2)
plot(l24g)
plot(l24g, center=1.5)
plot(l24g, center=2, include.center=FALSE)
plot(l24g, panel.arrange='h', wrap=20)
plot(l24g, panel.arrange='h', wrap=20)
title <- "How often do you read these materials because you want to?"
items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
head(items29); ncol(items29)
names(items29) = c("Magazines", "Comic books", "Fiction", "Non-fiction books", "Newspapers")
l29 <- likert(items29)
print(l29)
summary(l29)
# xtable
xtable(l29)
# Plots
plot(l29) + ggtitle(title)
install.packages(c("assertthat", "backports", "BH", "bindr", "bindrcpp", "Boom", "BoomSpikeSlab", "boot", "broom", "CausalImpact", "checkmate", "class", "cli", "clue", "clues", "cluster", "codetools", "colorspace", "curl", "data.table", "DBI", "dbscan", "devtools", "digest", "dplyr", "e1071", "evaluate", "flexclust", "foreach", "foreign", "Formula", "ggplot2", "git2r", "glue", "gmp", "gtable", "HH", "highr", "Hmisc", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "hunspell", "ipred", "irr", "iterators", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lazyeval", "leaps", "lmtest", "lpSolve", "markdown", "MASS", "Matrix", "mgcv", "mime", "mnormt", "modeltools", "multcomp", "munsell", "NLP", "nnet", "numDeriv", "openssl", "pkgconfig", "plogr", "plyr", "prodlim", "psych", "purrr", "R6", "randomForest", "Rcpp", "rJava", "RJSONIO", "rlang", "Rmpfr", "rpart", "rstudioapi", "sandwich", "scales", "servr", "shiny", "SnowballC", "sourcetools", "SparseM", "SQUAREM", "stopwords", "stringi", "stringr", "tau", "TH.data", "tibble", "tidyr", "tidyselect", "tidytext", "tm", "tokenizers", "topicmodels", "utf8", "vcd", "whisker", "withr", "XLConnect", "XLConnectJars", "xml2", "xtable", "xts", "yaml", "zoo"))
setwd("~/Dropbox/PhD/clustering/comparative/EE/R")
source("ee_clust.r")
## Project-Agnostic
#We have lda model and distance already:
load("../saved_data2/lda_2002.rda")             #lda_model
project_name <- "DAEMON"
source("ee_clust.r")
cat(paste("Now working on Project ", project_name, "...\n", sep=""))
data <- get_data("../SPDataset-PorruFilter", "train", project_name)
cat("Train Corpus Dimensions: ", dim(data), "\n")
test <- get_data("../SPDataset-PorruFilter", "valid", project_name)
cat("Validation Corpus Dimensions: ", dim(test), "\n")
#Append title and description into one column:
data$text <- paste(data$title, data$description, sep = " ")
test$text <- paste(test$title, test$description, sep = " ")
View(data)
data$labels <- cluster_h(data,
FE = "LDA",
verbose = T,
project_name = project_name,
ev = "sil",
test = test,
lda_model = lda_model)
results <- validate(data = data, project_name = project_name, FE = "LDA", type = "test", lda_model = lda_model)$results
View(results)
means <- aggregate(list(sp = data$storypoint, effort = data$effort.time, resolution = data$resolution.time, inprogress = data$in.progress.time),
list(label = data$label),
mean)
View(means)
medians <- aggregate(list(sp = data$storypoint, effort = data$effort.time, resolution = data$resolution.time, inprogress = data$in.progress.time),
list(label = data$label),
median)
View(medians)
type <- "test"
test <- get_data("../SPDataset-PorruFilter", type, project_name)
test$text <- paste(test$title, test$description, sep = " ")
View(test)
testing_text <- as.matrix(test$text)
View(testing_text)
test_size <- dim(testing_text)[1]
dtm.train <- posterior(lda_model)$topics
View(dtm.train)
dtm.test <- vsm(testing_text, verbose = F, weighting = weightTf)$dtmm
View(dtm.test)
dim(dtm.test)
dtm.test <- posterior(lda_model, dtm.test)$topics
View(dtm.test)
distance <- skmeans_xdist(dtm.test, dtm.train)
View(distance)
closest <- apply(distance, 1, which.min)
closest
closest.labels <- data$labels[closest]
closest.labels
data$labels
dim(distance)
dim(dtm.test)
dim(dtm.train)
training_text <- as.matrix(data$text)
train_size <- dim(training_text)[1]
dtm.train <- vsm(training_text, verbose = F, weighting = weightTf)$dtmm
dtm.train <- posterior(lda_model, dtm.train)$topics
stopifnot(dtm.train$nrow == train_size)
stopifnot(dtm.test$nrow == test_size)
dim(dtm.test)
distance <- skmeans_xdist(dtm.test, dtm.train)
dim(distance)
closest <- apply(distance, 1, which.min)
closest
stopifnot(length(closest) == test_size)
stopifnot(length(closest) != test_size)
closest.labels <- data$labels[closest]
closest.labels
dim(closest)
len(closest)
size(closest)
results <- data.frame(closest = closest,
sp = test$storypoint,
effort.t = test$effort.time,
resolution.t = test$resolution.time,
inprogress = test$in.progress.time,
closest.sp = data$storypoint[closest],
closest.effort.t = data$effort.time[closest],
closest.resolution.t = data$resolution.time[closest],
closest.inprogress = data$in.progress.time[closest],
mean.cluster.sp = means$sp[closest.labels],
mean.cluster.effort.t = means$effort[closest.labels],
mean.cluster.resolution.t = means$resolution[closest.labels],
mean.cluster.inprogress = means$inprogress[closest.labels],
median.cluster.sp = medians$sp[closest.labels],
median.cluster.effort.t = medians$effort[closest.labels],
median.cluster.resolution.t = medians$resolution[closest.labels],
median.cluster.inprogress = medians$inprogress[closest.labels]
)
ae.sp.cluster.median <- abs(results$sp - results$median.cluster.sp)
mae <- mean(ae.sp.cluster.median)
mdae <- median(ae.sp.cluster.median)
