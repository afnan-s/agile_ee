install.packages("wordnet")
install.packages("wordnet")
library("wordnet")
WNHOME
initDict()
Sys.getenv("WNHOME")
remove.packages("wordnet")
library("wordnet")
filter <- getTermFilter("ExactMatchFilter", "image", TRUE)
terms <- getIndexTerms("NOUN",1,filter)
getSynonyms(terms[[1]])
synonyms("image","VERB")
synonyms("view","VERB")
install.packages('causla impact')
install.packages('causalimpact')
install.packages("devtools")
library(devtools)
devtools::install_github("google/CausalImpact")
package(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("google/CausalImpact")
session_info()
install.packages('BoomSpikeSlab')
library(devtools)
devtools::install_github("google/CausalImpact")
library(CausalImpact)
set.seed(1)
x1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)
y <- 1.2 * x1 + rnorm(100)
y[71:100] <- y[71:100] + 10
data <- cbind(y, x1)
dim(data)
pre.period <- c(1, 70)
post.period <- c(71, 100)
impact <- CausalImpact(data, pre.period, post.period)
plot(impact)
summary(impact)
impact <- CausalImpact(data, pre.period, post.period, model.args = list(niter = 5000, nseasons = 7))
require(likert)
demo('likert', package='likert')
install.packages()
install.packages('ddply')
plot(l24, colors=c('orange','darkorange','darkblue','blue'))
plot(l24, include.histogram=TRUE)
require(grid)
require(plyr)
plot(l24, include.histogram=TRUE)
plot(l24, type='density')
plot(l24, type='density', facet=FALSE)
plot(l24, type='heat', wrap=30, text.size=4)
items24.reverse <- reverse.levels(items24)
l24.reverse <- likert(items24.reverse)
print(l24.reverse)
plot(l24.reverse)
l24g <- likert(items24, grouping=pisaitems$CNT)
print(l24g)
summary(l24g)
summary(l24g, center=1.5)
summary(l24g, center=2)
plot(l24g)
plot(l24g, center=1.5)
plot(l24g, center=2, include.center=FALSE)
plot(l24g, panel.arrange='h', wrap=20)
plot(l24g, panel.arrange='h', wrap=20)
title <- "How often do you read these materials because you want to?"
items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
head(items29); ncol(items29)
names(items29) = c("Magazines", "Comic books", "Fiction", "Non-fiction books", "Newspapers")
l29 <- likert(items29)
print(l29)
summary(l29)
# xtable
xtable(l29)
# Plots
plot(l29) + ggtitle(title)
install.packages(c("assertthat", "backports", "BH", "bindr", "bindrcpp", "Boom", "BoomSpikeSlab", "boot", "broom", "CausalImpact", "checkmate", "class", "cli", "clue", "clues", "cluster", "codetools", "colorspace", "curl", "data.table", "DBI", "dbscan", "devtools", "digest", "dplyr", "e1071", "evaluate", "flexclust", "foreach", "foreign", "Formula", "ggplot2", "git2r", "glue", "gmp", "gtable", "HH", "highr", "Hmisc", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "hunspell", "ipred", "irr", "iterators", "jsonlite", "KernSmooth", "knitr", "lattice", "lava", "lazyeval", "leaps", "lmtest", "lpSolve", "markdown", "MASS", "Matrix", "mgcv", "mime", "mnormt", "modeltools", "multcomp", "munsell", "NLP", "nnet", "numDeriv", "openssl", "pkgconfig", "plogr", "plyr", "prodlim", "psych", "purrr", "R6", "randomForest", "Rcpp", "rJava", "RJSONIO", "rlang", "Rmpfr", "rpart", "rstudioapi", "sandwich", "scales", "servr", "shiny", "SnowballC", "sourcetools", "SparseM", "SQUAREM", "stopwords", "stringi", "stringr", "tau", "TH.data", "tibble", "tidyr", "tidyselect", "tidytext", "tm", "tokenizers", "topicmodels", "utf8", "vcd", "whisker", "withr", "XLConnect", "XLConnectJars", "xml2", "xtable", "xts", "yaml", "zoo"))
setwd("~/Dropbox/PhD/clustering/comparative/EE/R")
load("../saved_data2/lda_2002.rda")
library(stringr)
library(RTextTools)
library(topicmodels)
library(SnowballC)
library(stringr)
library(tm)
library(cluster)
library(skmeans)
library(lsa)
d_g <- posterior(lda_model)$topics
View(d_g)
View(d_g)
dim(d_g)
summary(d_g)
head(d_g)
typeof(d_g)
d_g2 <- topics(lda_model, 4, 0.1)
View(d_g2)
dtm <- create_matrix(d_g2,
stemWords = FALSE,
removeStopwords = FALSE,
minWordLength = 1,
removePunctuation = TRUE,
weighting = tm::weightTfIdf
)
View(dtm)
rm(d_g2)
rm(dtm)
lda_model$call
lda_model@call
rm(lda_model)
dataset_size <- dim(d_g)[1]
vocaulary_size <- dim(d_g)[2]
if (verbose)
cat("Calculating distance matrix..", "\n")
start.time <- Sys.time()
distance <- as.dist(skmeans_xdist(d_g))
# cat(summary(distance), "\n")
end.time <- Sys.time()
time.taken <- end.time - start.time
save(distance, file = "distance_lda_2002.rda")
if (verbose == T)
cat("Time taken to calculate distance matrix: ", time.taken, "\n")
verbose = T
method = "ward.D2"
project_name = NULL
